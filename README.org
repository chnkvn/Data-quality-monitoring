#+TITLE: Data Quality Monitoring
#+autotangle: t
#+startup: overview
* Data Creation
- The first part of this project is to create fake data
- It should be requestable with an API
** Sensor
:properties:
# :header-args:python: :tangle src/sensor.py
:end:
*** class definition
#+begin_src python
import sys
from datetime import date, timedelta
import numpy as np
from attrs import define, field

@define
class Sensor:
    """Create a sensor that returns the number
    of visitors given a date and an hour."""

    avg_visit:int = field(converter=int)
    std_visit:float = field(converter=float)
    perc_break: float = field(converter=float, default=0.015)
    perc_malfunction: float = field(converter=float, default=0.035)
    open_hours = list(range(9, 22))

#+end_src
*** simulate_visit_count_method
#+begin_src python
    def simulate_visit_count(self, business_date: date) -> int:
        """Simulate the number of person detected by the sensor given a date and an hour"""

        # For reprocubility
        np.random.seed(seed=business_date.toordinal())

        # Get weekday of the business day
        weekday = business_date.weekday()

        # Generate the visitor counts over the working hours
        visits = np.random.normal(
            self.avg_visit, self.std_visit, size=len(self.open_hours)
        ) / len(self.open_hours)

        # More traffic on wednesdays (2), fridays (4), saturdays (5)
        if weekday == 2:
            visits *= 1.15
        elif weekday == 4:
            visits *= 1.2
        elif weekday == 5:
            visits *= 1.35
        # visitor count is set to -1 on sundays
        elif weekday == 6:
            visits *= 0
            visits -= 1
        return visits
#+end_src

*** get_visit_count method
#+begin_src python
    def get_visit_count(self, business_date:date, hour:int) -> int:
        """Returns the number of visitors from the store opening hour to the hour passed in parameters."""
        #For reprocubility
        np.random.seed(seed=business_date.toordinal())

        visitors_count = 0
        proba_malfunction = np.random.random()

        # The sensor can break sometimes
        # Also return 0 when hour in closing hours
        if proba_malfunction < self.perc_break or hour not in self.open_hours:
           return visitors_count
        if business_date.weekday() == 6:
           return -1
        visits = self.simulate_visit_count(business_date)
        # The sensor can also malfunction
        if proba_malfunction < self.perc_malfunction:
            visits *= 0.2  # make it so bad we can detect it ;)
        visits = np.floor(visits)
        for hour_, visit_count in zip(self.open_hours, visits):
                if hour_==hour:
                    visitors_count = visit_count
                    break
        return int(visitors_count)
#+end_src
*** __main__
#+begin_src python
if __name__ == "__main__":
    if len(sys.argv) > 2:
        year, month, day = [int(v) for v in sys.argv[1].split("-")]
        hour = int(sys.argv[2])
    else:
        year, month, day = 2023, 10, 25
        hour = 18
    queried_date = date(year, month, day)

    captor = Sensor(1500, 150)
    print(captor.get_visit_count(queried_date, hour))
#+end_src
** Store
:properties:
# :header-args:python: :tangle src/store.py
:end:
*** class definition
#+begin_src python
from datetime import date

import numpy as np
from attrs import define, field
from data_quality_monitoring.src.sensor import Sensor

@define
class Store:
    name:str = field(converter=str)
    avg_visit: int = field(converter=int)
    std_visit: float = field(converter=float)
    perc_malfunction:float = field(default=0)
    perc_break:float = field(default=0)
    sensors = field(init=False)

    def __attrs_post_init__(self):
        # To always get the same result when asking for the same store
        seed = np.sum(list(self.name.encode("ascii")))
        np.random.seed(seed=seed)
        # Let assume every store has 5 captors
        traffic_percentage = {0.49, 0.31, 0.1, 0.07, 0.03}
        self.sensors = [
            Sensor(percent * self.avg_visit,
                   percent* self.std_visit,
                   self.perc_break,
                   self.perc_malfunction)
            for percent in traffic_percentage
        ]
#+end_src
*** get sensor traffic
#+begin_src python
    def get_sensor_traffic(self, sensor_id : int, requested_date:date, hour:int) -> int:
        """Return the traffic of a sensor given a date and an hour"""
        return self.sensors[sensor_id].get_visit_count(requested_date, hour)
#+end_src
*** get store traffic
#+begin_src python
    def get_store_traffic(self, requested_date:date, hour:int) -> int:
        """Return the traffic of all the sensors given a date and an hour"""
        traffic = sum(sensor.get_visit_count(requested_date, hour) for sensor in self.sensors)
        return traffic
#+end_src
*** __main__ :noexport:
#+begin_src python
if __name__ == '__main__':
    lille_store = Store("Test", 1200, 300)
    visits = lille_store.get_store_traffic(date(2023, 12, 21), 18)
    print(visits)
#+end_src
** init
:properties:
# :header-args:python: :tangle __init__.py
:end:
#+begin_src python
from datetime import date

from data_quality_monitoring.src.store import Store


def create_data() -> dict:
    """
    Create the available stores in our API
    5 stores, with each 5 sensors
    Each stores has a different number of people coming to it
    As well as different break and malfunction percentages
    (Not realistic, but we keep things simple)
    """

    store_name = ["Nancy", "Paris", "Lille", "Cholet", "Cabourg"]
    store_avg_visit = [4444, 8000, 5600, 2000, 2750]
    store_std_visit = [2800, 750, 1200, 300, 1000]
    perc_malfunction = [0.05, 0.1, 0.08, 0.05, 0.05]
    perc_break = [0.05, 0.08, 0.05, 0.02, 0]

    store_dict = {tuple_[0]: Store(*tuple_)
                  for tuple_  in zip(store_name,
                                     store_avg_visit,
                                     store_std_visit,
                                     perc_break,
                                     perc_malfunction)}

    return store_dict

if __name__ == '__main__':
    print(create_data())

#+end_src


** Unit tests
*** sensors
:properties:
#  :header-args:python: :tangle tests/test_sensors.py
:end:
#+begin_src python
import unittest
from datetime import date

import numpy as np
from data_quality_monitoring.src.sensor import Sensor

class TestVisitSensor(unittest.TestCase):
    def test_weekdays_open(self):
        for test_day in range(11, 17):
            with self.subTest(i=test_day):
                visit_sensor = Sensor(1200, 300)
                visit_count = visit_sensor.simulate_visit_count(date(2023, 9, test_day))
                self.assertFalse(-1 in set(visit_count))

    def test_sunday_closed(self):
        visit_sensor = Sensor(1200, 300)
        visit_count = visit_sensor.simulate_visit_count(date(2023, 9, 17))
        self.assertEqual(set(visit_count), {-1})

    def test_with_break(self):
        visit_sensor = Sensor(1500, 150, perc_break=15)
        visit_count = visit_sensor.get_visit_count(date(2023, 10, 12), 20)
        self.assertEqual(visit_count, 0)

    def test_with_malfunction(self):
        visit_sensor = Sensor(1500, 150, perc_malfunction=15)
        visit_count = visit_sensor.get_visit_count(date(2023, 10, 12), 20)
        self.assertEqual(visit_count, 20)


if __name__ == "__main__":
    unittest.main()
#+end_src

*** store
:properties:
 # :header-args:python: :tangle tests/test_store.py
:end:
#+begin_src python
import unittest
from datetime import date

from data_quality_monitoring.src.store import Store


class TestStore(unittest.TestCase):
    def test_get_store_traffic(self):
        lille_store = Store("Test", 1200, 300)
        visits = lille_store.get_store_traffic(date(2023, 12, 21), 18)

        self.assertEqual(visits, 111)

    def test_get_sensor_traffic(self):
        lille_store = Store("Test", 1200, 300)
        visits = lille_store.get_sensor_traffic(3, date(2023, 12, 21), 18)

        self.assertEqual(visits, 35)

    def test_sunday_closed(self):
        lille_store = Store("Test", 1200, 300)
        visits = lille_store.get_sensor_traffic(2, date(2024, 1, 7), 18)
        self.assertEqual(visits, -1)


if __name__ == "__main__":
    unittest.main()
#+end_src

* API
  :PROPERTIES:
#  :header-args:python: :tangle app.py
  :END:
- Creation of an api with FastAPI
- We create it to simulate the provider's API, here the API is deployed locally.
To launch the api locally, run ~uvicorn app:app --reload~
#+begin_src python
import logging
from datetime import date

from fastapi import FastAPI
from fastapi.responses import JSONResponse
from data_quality_monitoring import create_data

store_dict = create_data()
app = FastAPI()


@app.get("/")
def get_nb_visitors(store_name: str="Nancy", year: int=2021, month: int=1, day: int=25,  hour: int = 21, sensor_id: int | None = None) -> JSONResponse:
    # Check the year
    if year < 2020:
        return JSONResponse(status_code=404, content="No data before 2020")

    # Check the date
    try:
        requested_date = date(year, month, day)
    except ValueError as e:
        logging.error(f"Could not cast date: {e}")
        return JSONResponse(status_code=404, content="Enter a valid date")

    # Check the date is in the past
    if date.today() < requested_date:
        return JSONResponse(status_code=404, content="Choose a date in the past")
    if sensor_id is None:
        visit_counts = store_dict[store_name].get_store_traffic(requested_date, hour)
    elif sensor_id not in range(len(store_dict[store_name].sensors)):
         return JSONResponse(status_code=404,
                             content=(f"Sensor #{sensor_id} does not exist. "
                             f"This store only have {len(store_dict[store_name].sensors)} sensors."))
    else:
        visit_counts = store_dict[store_name].get_sensor_traffic(
            sensor_id, requested_date, hour
        )
    if visit_counts < 0 or hour not in store_dict[store_name].sensors[0].open_hours:
        return JSONResponse(
            status_code=404, content="The store was closed try another date or hour."
        )
    return JSONResponse(status_code=200, content=visit_counts)
#+end_src

* Data Extraction
  :PROPERTIES:
 # :header-args:python: :tangle data_extraction.py
  :END:
The goal is to request the API to build our data.
You must deploy the API locally before running the script.
** Imports, constants
#+begin_src python
import sys
from pathlib import Path
from datetime import date, timedelta
import pandas as pd
import requests

date_ex = date(2023, 1, 25)
#+end_src

** Request api
#+begin_src python
def request_api(store_name:str = "Nancy", day:date =  date_ex,
                hour:int=21, sensor_id:int=0, url="http://127.0.0.1:8000/"):
    """Request information from an API"""
    if len(sys.argv) > 1:
        store_name:str = sys.argv[1]
        day:date = date(*tuple(int(v) for v in sys.argv[2].split("-")))
        hour:int=sys.argv[3]
        sensor_id:int=sys.argv[4]
    assert type(day) == date
    params = {"store_name": store_name,
              'year':day.year,
              "month":day.month,
              "day":day.day,
              "hour":hour,
              "sensor_id":sensor_id}
    r = requests.get(url, params=params)
    return r.content
#+end_src

** Generate csv
#+begin_src python
def generate_csv():
    """Generate csv containing sensors data, 1 csv per month"""

    # Create data/raw if it does not exist
    save_path = 'data/raw'
    Path(save_path).mkdir(parents=True, exist_ok=True)

    # Generate dataframe  containing the data for each month, until we reach the current date
    current_day = date(2020, 1,1)
    data = []
    while current_day < date.today():
        for store in {"Nancy", "Paris", "Lille", "Cholet", "Cabourg"}:
            for hour in range(9,22):
                for sensor_id in range(5):
                    data.append([current_day, hour, store, sensor_id,
                                 request_api(store, current_day, hour, sensor_id), 'visitors', current_day.weekday()])
        next_day = current_day + timedelta(days=1)
        # if new month, generate and save the dataframe
        if next_day.month > current_day.month:
            df = pd.DataFrame(data)
            df.rename(columns={0:'date', 1: 'hour', 2: 'store', 3:'sensor_id', 4: 'count', 5:'units', 6: 'weekday'}, inplace=True)
            noise_df1 = df.sample(frac=0.1)
            noise_df1['units'] = 'items'
            noise_df2 = df.sample(frac=0.15)
            noise_df2['sensor_id'] = 'NULL'
            dataframe = pd.concat([df, noise_df1, noise_df2]).sample(frac=1)
            dataframe.to_csv(f'{save_path}/{current_day.year}-{current_day.month:02d}.csv',
                             index=False)
            # reset the list containing the data
            data = []
        # extract data about the next day
        current_day=next_day
    return
        
                
#+end_src
** __main__
#+begin_src python
if __name__ == '__main__':
    generate_csv()

#+end_src
* Transform Data
  :PROPERTIES:
:header-args:python: :tangle data_transformation.py
  :END:
** Import
#+begin_src python
from pathlib import Path

import pandas as pd
import duckdb

#+end_src
** Read data
#+begin_src python
def read_data() -> pd.DataFrame:
    df = pd.DataFrame()
    raw_data_folder = Path.cwd().joinpath('data', 'raw')
    # Concatenate all csv into one dataframe
    for file in raw_data_folder.glob('*.csv'):
        csv_path = raw_data_folder.joinpath(file)
        df = pd.concat([df, pd.read_csv(csv_path)])

    # Remove duplicate rows
    df = df.drop_duplicates()
    # count column is composed of str values
    # Keep only the numbers, replace others values by NaN
    df['count'] = df['count'].str.replace(r"b'(\d+| )'",r'\1', regex=True)
    df['count'] = pd.to_numeric(df['count'], errors="coerce")
    return df
#+end_src
** daily trafic
#+begin_src python
def get_daily_traffic_per_store(df:pd.DataFrame) -> pd.DataFrame:
    """Keep rows where:
    - units value is equal to visitor
    - sensor_id is not a null value"""
    query = """SELECT date, store, sensor_id, weekday, sum(count) as daily_traffic FROM df
    WHERE units == 'visitors' and sensor_id IS NOT NULL
    GROUP BY date, weekday, store, sensor_id
    ORDER BY date, store, sensor_id
    """
    result_df = duckdb.sql(query).df()
    return result_df
#+end_src
** traffic average over 1 month
#+begin_src python
def traffic_average_week(df:pd.DataFrame, n_week:int = 4):
    """Compute the moving average over the last $n_weeks weeks"""
    query = f"""
    SELECT date,
    store,
    weekday,
    sensor_id,
daily_traffic,
    AVG(daily_traffic)
    OVER(PARTITION BY weekday, store, sensor_id
    ORDER BY date
    ROWS BETWEEN  {n_week-1} PRECEDING AND CURRENT ROW)
    AS avg_n_weeks
    from df
    ORDER BY date, sensor_id, store
    """
    return duckdb.sql(query).df()
#+end_src
** percentage_change
#+begin_src python
def pct_traffic_average_week(df:pd.DataFrame, n_week:int = 4):
    """Compute the percentage change between the moving average
    and the average of the current week"""
    query = f"""
    SELECT date, store, weekday, sensor_id,
    daily_traffic, avg_n_weeks,
    LAG(avg_n_weeks)
    OVER(PARTITION BY weekday, store, sensor_id
    ORDER BY date)  AS lag_avg_n_weeks,
    (100*(avg_n_weeks - lag_avg_n_weeks)/lag_avg_n_weeks) as pct_change
    from df
    """
    return duckdb.sql(query).df()

#+end_src
** save_df_to_parquet
#+begin_src python
def save_df_to_parquet(df:pd.DataFrame):
    """Create the folder filtered in data/ and save the dataframe to a parquet file"""
    save_path = 'data/filtered'
    Path(save_path).mkdir(parents=True, exist_ok=True)
    df.to_parquet(Path(save_path, 'df.parquet.gzip'),
              compression='gzip', index=False)

#+end_src

** generate_filtered_data
#+begin_src python
def generate_filtered_data():
    df =  read_data()
    df= get_daily_traffic_per_store(df)
    df = traffic_average_week(df)
    df = pct_traffic_average_week(df)
    save_df_to_parquet(df)

#+end_src
** __main__
#+begin_src python
if __name__ == '__main__':
   generate_filtered_data()


#+end_src
* App
:properties:
  :header-args:python: :tangle app_streamlit.py
:end:
** Imports
#+begin_src python
import duckdb
import pandas as pd
import streamlit as st

df = pd.read_parquet('data/filtered/df.parquet.gzip')
print(df.shape)
print(df.columns)
#+end_src
** List of stores, sensors
#+begin_src python
st.dataframe(df.sample(frac=1).head(50))
with st.sidebar:
    available_stores_df = duckdb.sql('SELECT store from df').df()
    store = st.selectbox('Pick a store to check its stats.',
                         available_stores_df['store'].unique(),
                         index=None,
                         placeholder='Pick a store')
    if store:
        st.write(f'Selected store: {store}')
        available_sensors_df = duckdb.sql(f'SELECT DISTINCT sensor_id from df where store = {store}')

st.header("enter your code:")
form = st.form("my_form")
query = form.text_area(label="votre code SQL ici", key="user_input")
form.form_submit_button("Submit")
    
#+end_src
